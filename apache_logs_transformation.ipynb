{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38dcb288",
   "metadata": {},
   "source": [
    "# AWS Glue Studio Notebook\n",
    "##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d56ce1a",
   "metadata": {},
   "source": [
    "#### Import libraries and initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecab756",
   "metadata": {},
   "outputs": [],
   "source": [
    "%idle_timeout 2880\n",
    "%glue_version 5.0\n",
    "%worker_type G.1X\n",
    "%number_of_workers 5\n",
    "\n",
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "from pyspark.sql.functions import col, when, hour, date_format, to_timestamp\n",
    "  \n",
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd8c8e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Read the data from the Glue Catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59796b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the table name from your Glue Data Catalog\n",
    "database_name = \"security_logs_db\"\n",
    "table_name = \"raw_apache_logs_txt\"  # Use your actual table name\n",
    "\n",
    "# Read the raw apache logs\n",
    "datasource = glueContext.create_dynamic_frame.from_catalog(\n",
    "    database=database_name,\n",
    "    table_name=table_name\n",
    ")\n",
    "\n",
    "# Convert to DataFrame for easier processing\n",
    "df = datasource.toDF()\n",
    "\n",
    "# Look at the schema\n",
    "df.printSchema()\n",
    "\n",
    "# Display a few rows to understand the data\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5925de",
   "metadata": {},
   "source": [
    "![output1](images\\root.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ed766a",
   "metadata": {},
   "source": [
    "#### Clean and transform the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3631e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the schema we saw in the previous step, process the data\n",
    "# The column names will match what we saw in your schema image\n",
    "\n",
    "# Process the data based on your schema\n",
    "processed_df = df.select(\n",
    "    col(\"clientip\").alias(\"ip\"),\n",
    "    col(\"timestamp\"),\n",
    "    col(\"verb\").alias(\"method\"),\n",
    "    col(\"request\").alias(\"endpoint\"),\n",
    "    col(\"httpversion\").alias(\"http_version\"),\n",
    "    col(\"response\").cast(\"integer\").alias(\"status_code\"),\n",
    "    col(\"bytes\").cast(\"integer\"),\n",
    "    col(\"referrer\"),\n",
    "    col(\"agent\").alias(\"user_agent\")\n",
    ")\n",
    "\n",
    "# Convert timestamp string to proper timestamp\n",
    "processed_df = processed_df.withColumn(\n",
    "    \"timestamp_parsed\", \n",
    "    to_timestamp(col(\"timestamp\"), \"dd/MMM/yyyy:HH:mm:ss Z\")\n",
    ")\n",
    "\n",
    "# Add security-relevant columns\n",
    "security_df = processed_df \\\n",
    "    .withColumn(\"hour_of_day\", hour(col(\"timestamp_parsed\"))) \\\n",
    "    .withColumn(\"date\", date_format(col(\"timestamp_parsed\"), \"yyyy-MM-dd\")) \\\n",
    "    .withColumn(\"is_error\", when(col(\"status_code\") >= 400, 1).otherwise(0)) \\\n",
    "    .withColumn(\"is_client_error\", when((col(\"status_code\") >= 400) & (col(\"status_code\") < 500), 1).otherwise(0)) \\\n",
    "    .withColumn(\"is_server_error\", when(col(\"status_code\") >= 500, 1).otherwise(0)) \\\n",
    "    .withColumn(\"is_potential_attack\", when(\n",
    "        (col(\"endpoint\").like(\"%../../../%\")) |  # Path traversal attempts\n",
    "        (col(\"endpoint\").like(\"%exec%\")) |       # Command execution attempts\n",
    "        (col(\"endpoint\").like(\"%select%\")) |     # SQL injection attempts\n",
    "        (col(\"endpoint\").like(\"%union%\")) |      # SQL injection attempts\n",
    "        (col(\"endpoint\").like(\"%script%\")),      # XSS attempts\n",
    "        1).otherwise(0))\n",
    "\n",
    "# Display sample of the enriched data\n",
    "security_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84509828",
   "metadata": {},
   "source": [
    "![output2](images\\image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c8aecd",
   "metadata": {},
   "source": [
    "#### Get some summary statistics on the security data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c8e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total records\n",
    "total_logs = security_df.count()\n",
    "print(f\"Total log entries: {total_logs}\")\n",
    "\n",
    "# Count errors by type\n",
    "error_count = security_df.filter(col(\"is_error\") == 1).count()\n",
    "client_error_count = security_df.filter(col(\"is_client_error\") == 1).count()\n",
    "server_error_count = security_df.filter(col(\"is_server_error\") == 1).count()\n",
    "attack_count = security_df.filter(col(\"is_potential_attack\") == 1).count()\n",
    "\n",
    "print(f\"Error responses: {error_count} ({error_count/total_logs*100:.2f}%)\")\n",
    "print(f\"Client errors: {client_error_count} ({client_error_count/total_logs*100:.2f}%)\")\n",
    "print(f\"Server errors: {server_error_count} ({server_error_count/total_logs*100:.2f}%)\")\n",
    "print(f\"Potential attacks: {attack_count} ({attack_count/total_logs*100:.2f}%)\")\n",
    "\n",
    "# Get top 5 IP addresses with most requests\n",
    "print(\"\\nTop 5 IP addresses by request count:\")\n",
    "security_df.groupBy(\"ip\").count().orderBy(col(\"count\").desc()).show(5)\n",
    "\n",
    "# Get top 5 requested endpoints\n",
    "print(\"\\nTop 5 requested endpoints:\")\n",
    "security_df.groupBy(\"endpoint\").count().orderBy(col(\"count\").desc()).show(5)\n",
    "\n",
    "# Count requests by hour of day\n",
    "print(\"\\nRequests by hour of day:\")\n",
    "security_df.groupBy(\"hour_of_day\").count().orderBy(\"hour_of_day\").show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3545f99d",
   "metadata": {},
   "source": [
    "![output3](images\\summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d31cc7",
   "metadata": {},
   "source": [
    "#### Select final columns and save the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e26869",
   "metadata": {},
   "source": [
    "# Select the final columns for our security analysis\n",
    "final_df = security_df.select(\n",
    "    \"ip\", \"timestamp\", \"timestamp_parsed\", \"date\", \"hour_of_day\", \n",
    "    \"method\", \"endpoint\", \"http_version\", \"status_code\", \"bytes\",\n",
    "    \"is_error\", \"is_client_error\", \"is_server_error\", \"is_potential_attack\",\n",
    "    \"referrer\", \"user_agent\"\n",
    ")\n",
    "\n",
    "# Define the output path\n",
    "\n",
    "output_path = \"s3://security-log-analysis-bucket/security-log-analysis-bucket-database/security-log-analysis-transformed/\"\n",
    "\n",
    "# Convert back to DynamicFrame\n",
    "output_dyf = DynamicFrame.fromDF(final_df, glueContext, \"output_dyf\")\n",
    "\n",
    "# Write the transformed data to S3\n",
    "glueContext.write_dynamic_frame.from_options(\n",
    "    frame=output_dyf,\n",
    "    connection_type=\"s3\",\n",
    "    connection_options={\"path\": output_path},\n",
    "    format=\"parquet\"\n",
    ")\n",
    "glueContext.write_dynamic_frame.from_options(\n",
    "    frame=output_dyf,\n",
    "    connection_type=\"s3\",\n",
    "    connection_options={\"path\": output_path},\n",
    "    format=\"json\"\n",
    ")\n",
    "\n",
    "print(\"Transformation complete. Data written to:\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaf0b74",
   "metadata": {},
   "source": [
    "Output: Transformation complete. Data written to: s3://security-log-analysis-bucket/security-log-analysis-bucket-database/security-log-analysis-transformed/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
